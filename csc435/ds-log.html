<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.3/css/bootstrap.min.css" integrity="sha384-Zug+QiDoJOrZ5t4lssLdxGhVrurbmBWopoEl+M6BdEfwnCJZtKxi1KgxUyJq13dy" crossorigin="anonymous">

    <title>Brandon Markwalder's Study Log</title>
</head>
<body>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.3/js/bootstrap.min.js" integrity="sha384-a5N7Y/aK3qNeh15eJKGWxsqtnX/wWdSZSKp+81YjTmS15nvnvxKHuzaWwXHDli+4" crossorigin="anonymous"></script>

<div class="container">
    <div class="row">
        <div class="col-12">

            <h2 class="text-center">Brandon Markwalder's Study Log</h2>
            <h3 class="text-center">Word count: 9269</h3>

            <h3>20 Concepts:</h3>

            <p class="font-weight-bold">01. Transparency:</p>
            <p>Transparency is an effort to make the distributed system invisible to the user. A main goal of transparency is to hide the architecture of the various systems in the distributed system. If the architecture is hidden that means an agreement is in place on how data is represented, meaning it does not matter what kind of machine, or operating system is currently involved in the system and reading or manipulating the data.</p>
            <p>There are several types of transparency to consider. Location transparency refers to not knowing the location of a data object, process, or thread within the system. URLs are a good example of location transparency. brandonmarkwalder.com tells the end user nothing about the fact that the files that drive my site sit on a virtual private server somewhere in New York. A related type is relocation transparency which simply states that the end user cannot tell if the files have been moved from one location to another. Concurrency transparency is the effect of hiding the use of shared files and resources. With concurrency transparency, Bob would not be aware that Alice is currently reading data from the same table as he is at the same time. Most importantly we have failure transparency, which prevents the user from knowing that a part of the system has failed. Failure transparency is generally difficult to achieve, mainly because it is often hard to distinguish between a process that has failed and one that is simply taking a long time to complete.</p>
            <p>Transparency is not always a good thing. The following example inspired by one provided in class demonstrates this concept swimmingly:</p>
            <p>You are developing a time lapse video of a seasonal change as a fun project with your toddler. The general workflow is to have the camera send a video stream to a remote location so you can review a day’s worth of images quickly and choose the one that best fits the motif of the film. However, that video stream goes down because a certain toddler unplugged the cable modem. Knowing that the system has a backup 2400 baud modem, you call your wife and tell her to hit the big red button which fires up the low bandwidth connection and tells the system to send a single image. Although we did not have a video stream to choose a best image from, we do still have the day captured, meaning the time lapse photo series completely captures the seasonal change.</p>

            <p class="font-weight-bold">02. Interface Definition Language (IDL):</p>
            <p>An IDL is a construct that helps open systems by defining the contract of the open system. The IDL defines an interface; input, output, return values, methods, data streams, and data types. IDLs allow contributing parties to the open system to remain free from implementation restrictions. IDLs are so carefully defined that they can be checked for syntax violations, as well as produce helper code such as client stubs and server skeletons. However, this helper code is a nice to have, a side effect of the contract. The whole point of an IDL is the agreement between the contributing parties on what the system will consume and produce. Any language, platform, architecture, etc. can be used in the open system, as long as the contract of the system (IDL) is respected. </p>

            <p class="font-weight-bold">03. Inter process communication (IPC):</p>
            <p>A process is how a computer assigns and performs work to be done. There are many processes running simultaneously on any given system. These processes often need to talk to each other to perform their jobs. They communicate by sending messages, defined as inter process communication (IPC). IPC is an easy feat on a local system as a shared memory block can be allocated for them to pass messages, variables, parameters, etc. between each other. IPC becomes tricky when we need processes of the same distributed system to communicate even though they may be running on different local machines. There is no global shared memory for them to use, so the processes must send messages across the network. Sending messages over the network leads to a compromise between performance and reliability.</p>

            <p class="font-weight-bold">04. Architectural Styles:</p>
            <p>There are a handful architectural styles to consider, including layered based, object based, data centered, and event based.</p>
            <p>With layered based architecture, events are pushed through various layers of the system. The typical layers involved are the user-interface, processing, and the data layers. We publish events down through layers of the system and responses flow back up.</p>
            <p>When we talk about object based events in distributed systems, they are really only there to protect data. Using objects over a network is just like making method calls that include a port number and an IP address.</p>
            <p>Event-based architecture can be boiled down to the notion that there are two types of event busses. You can publish to an event bus or you can consume from an event bus. Publishers publish events to the system and we rely on middleware to coordinate those events such that only the subscribed processes receive the published events. The key to remember is that the processes in event based architecture are referentially decoupled. The even bus acts as the middleware, and it handles getting the data to the correct consumer. The publisher and the consumer do not need to know about each other, the bus handles those details.</p>
            <p>Data-centered architectures requires that data shared in a persistent state. Persistent busses are much harder to implement, but with that difficulty comes higher performance. Data-centered architectures user temporal decoupling otherwise stated as the process are time independent of each other because the data is persistent. This concept relies on middle ware to coordinate message delivery between processes, however, the consumer processes can be in any state when an event is published because the middleware will ensure that subscribed processes will receive the message once they are available to do so. Again this is possible because of data persistence.</p>

            <p class="font-weight-bold">05. Multi-tiered architectures:</p>
            <p>Multi-tiered architectures involve client and server machines and how we distribute a code base between them. The simplest form is to have clients with code to drive only the user interface, with all other parts of the application living on the server. There are two extremes to this approach, thick and thin, and often the best solution is somewhere in between.</p>
            <p>The majority of code lives client side with thin clients, whereas the majority of code lives server side with thin clients. Both have pros and cons, so again you have to find a balance for each application. To simply the comparison we will look at pros and cons of heavy clients and heavy servers.</p>
            <p>Heavy clients result in less network traffic, which means they are often snappier and are more secure from data interception / snooping. The computational requirements for the application are shifted to the client and we can offload data security and liability to the client. Heavy clients result in the code base being distributed to many devices which can lead to offline push problems. In other words, it becomes very difficult to ensure that the code base remains up-to-date and secure as not all devices will be online all the time to receive updates.</p>
            <p>Heavy servers result in code bases that are easier to maintain because the code resides at home base, not spread out across the distributed system. They are often simpler because the bulk of the code is centrally located. We also can benefit from increased security, again because of centrally located code. Heavy clients suffer when it comes to computationally expensive code as the server provides the bulk of the processing power and we need to send and receive all of that data between the server and the clients. Finally, if we are working with sensitive data, we have to concern ourselves with protecting that data server side and assume the liabilities associated with storing such data.</p>

            <p class="font-weight-bold">06. Data marshalling:</p>
            <p>Data marshalling is extremely valuable as it allows many different platforms to talk to each other regardless of architecture. Marshalling also makes debugging systems cheap, easy, and fast. The first step in marshalling data is converting program data that is stored in memory from random access data to serialized data that can then be sent bit by bit over a network.</p>
            <p>Marshalling requires work from the programmer as automation is next to impossible considering that there are a lot of different computer architectures, different ways of encoding integers (big-endian and littler endian), different floating point accuracies, and different character encodings. Complex data structures are also difficult to marshal without programmer intervention. It is bad to ask simple algorithms to understand dynamic data structures like random access cyclically linked lists – what happens when the points in the list change? Without programmer intervention, bad things, that is what happens with automated marshalling.</p>
            <p>If marshalling takes work, then why bother? Again, it makes data available to all types of systems in a distributed system. Data that has been marshalled and then serialized into bits, is extremely easy to send over a network. On the other side, once the data has been unmarshalled, it can be integrated into whatever platform the receiving end is running on. Finally marshaled data is very easy to debug in transit. For example, if examining a packet, what is easier for the human programmer to identify?</p>
            <li>Non marshalled integer: 0000000101000011</li>
            <li>Marshalled integer: &lt;Integer&gt;0323&lt;Integer&gt;</li>
            <p></p>

            <p class="font-weight-bold">07. Request-reply communication (RPC):</p>
            <p>RPC is a basic form of serialized communication is request-reply communication (RPC). A client sends a request over the network. The server receives the request, selects and executes the called objects and methods, and returns the result as a reply. The typical message structure of a RPC message structure is as follows:</p>
            <li>Message type: int</li>
            <li>Request ID: int</li>
            <li>Referenced object(s): pointer / reference</li>
            <li>Method ID(s): int or method name</li>
            <li>Arguments: array</li>
            <p></p>
            <p>RPC uses a set of standard protocols which should be selected from depending on the requirements of the open system. Again, the common theme of compromise will aide in which protocol to use. The RPC protocols are:</p>
            <li>R: Request</li>
            <li>RR: Request, reply</li>
            <li>RRA: Request, reply, acknowledge</li>
            <p></p>
            <p>A handy trick to save on network traffic is to piggy back the acknowledgement onto a reply. This works best when we do not need to know immediately that a message was received, and when there is a lot of communication between the client and the server, and the client is synchronous.</p>
            <p>Some of the challenges with RPC include messages getting lost or delayed, and either the server or the client timing out. To mitigate these challenges it is useful to keep a history of the conversation. The history is used to prevent duplicate messages from being sent when we do not want an action to be executed twice if the first message was delayed in transit. The history typically contains the message ID and the client to which the message was sent.</p>

            <p class="font-weight-bold">08. Java serialization:</p>
            <p>The key point in java serialization is that metadata is sent along with the data to keep things in sync and tidy. If an object references another object, both must be included in the serialized stream, even if the referenced object is not used. The metadata sent allows for version checking, which is crucial in distributed systems, especially because various clients can go off line and become out of date. Class information, data types, and instance variable names are included in the metadata. References are treated as handles, which point to an object, this allows for the object to be decoded only once, rather than every time it is referenced. The order in which the data is sent is as follows: The number of variables, followed by the types of the variables, finally followed by the values of the variables. When we are sending strings, the length of the string prepends the actual serialized string. To summarize the entire process, we first wrap our method for writing an object in and object output stream, and then pass the object to be serialized in as a parameter. On the other end, we wrap our method for reading objects in an object input stream, and pass in the serialized message for decoding. All of this is built into Java, so it is super easy to implement.</p>
            <p>A specific form of Java serialization is Remote Method Invocation (RMI). RMI is exactly what it sounds like. We have a process or operation on the client side that sends a request to the server side. The request is received, and the appropriate object is selected and the called methods are executed. The result is then sent back to the client. While the server processes the request, the clients waits.</p>

            <p class="font-weight-bold">09. Data Streams:</p>
            <p>Data Streams are most basically defined as a sequence of data units. Data streams are a convenient way of sending multimedia data over a network. In its basic architecture we have a bank of multimedia data to which we want to send over the network. We feed this data into a multimedia server which has a Quality of Service (QOS) control mechanism that we send all of our data through. The data arrives on the client side and is fed in through the clients QOS and then onto be decoded.</p>
            <p>Data streams can be used to send discrete or units like a joke, or continuous units like video and audio. Data streams are said to be in asynchronous transmission mode when the data units that are sent in order, one after the other with no timing constraints. Data streams are said to be in synchronous transmission mode when there are no constraints on data units arriving early. Isochronous transmission mode is for data units that need to be transferred precisely on time, otherwise stated as they cannot arrive early nor late. In isochronous data streams, we can run into buffer problems if data units arrive early, and out of sync data problems if they arrive too late. Isochronous transmission requires constraints on the amount of jitter in the data stream. Jitter is the time variance between units being transferred in the stream. More simply put, jitter is the time difference between the speediest and the slowest packet. Streaming data is defined as continuous data units being sent in isochronous transmission mode.</p>
            <p>If asked a question about data streams to which you do not know the answer, you are almost always going to be correct in saying “we need bigger buffers”.</p>
            <p>Data streams can be simple or complex. Simple streams are comprised of sequenced data, whereas complex streams are comprised of multiple related sub-streams. Video is a classic example of a complex stream as we commonly have the video stream coupled with multiple audio streams.</p>
            <p>The QOS on either side of the stream is responsible for determining when and how to downgrade the data units to provide the best unit quality while adhering to the required transmission mode for the particular type of data being streamed. Parameters that the QOS considers are:</p>
            <li>Required bit rate</li>
            <li>Maximum delay for session setup</li>
            <li>Maximum end-to-end and round-trip delay</li>
            <li>Maximum jitter</li>
            <p></p>
            <p>Bigger buffers allow us to reduce jitter. The bigger the buffers are, the more likely we can deal with variance in data streams. The compromise we make with bigger buffers is a longer start up time as the buffer is filled.</p>

            <p class="font-weight-bold">10. Encryption:</p>
            <p>There are several parts to encrypting data including the various forms of encryption; symmetric, public key, etc. and the supporting mechanisms such as certificate sites and oracles.</p>
            <p>The most common form of encryption is symmetric key encryption and it is usually the type of encryption applied against passwords to log into systems. It is cheap, fast, and generally a very robust form of encryption. Both parties share the same key, hence the term symmetric. The difficulty in this form is distributing the key to all parties involved.</p>
            <p>Public key encryption uses non-symmetric keys, one to encrypt the data and the other to decrypt the data. Either key can be used for either process. The most common form of public key encryption is the Rivest Shamir Adleman (RSA) algorithm. Key pairs are easy to create using various forms of free-ware. Both keys of the pair are functionally the same, and you simply define one as your public key and the other as your private key. The important parts to remember about how we use public and private keys:</p>
            <li>Alice would use Bob’s public key to send Bob a secret message</li>
            <li>Alice would use her private key to sign a document which Bob could later decrypt using Alice’s public key</li>
            <p></p>
            <P>Oracles are trusted entities that serve as a supporting mechanism to public key encryption. They post bindings of the public keys to stakeholders. More simply put, they are trusted repositories of names and their associated public keys. Oracles were created by companies simply stating, you can trust us. A classic example is Verisign. Their credibility was established only by them saying they were trustworthy and that they have operated in that capacity over time. The Oracles allow us to go get someone’s public key and send them a secret message. Going the other direction, they allow us to retrieve a public key to verify that someone signed a document. Oracles can offload work to certification sites.</P>
            <p>In order for the entire system to work, we must trust that the oracle is providing us the name of someone and their associated public key, and that their secret key has not been leaked.</p>
            <p>When entering business relationships that require encryption messaging, you can trust that the other party cannot claim they simply lost their key; resulting in an unauthorized message, by building into the contract terms that state the following: It’s ok if your private key is leaked, we can redo everything, at a cost of the full contract value.</p>

            <p class="font-weight-bold">11. Distributed hash table (DHT) multicast:</p>
            <p>Distributed hash table (DHT) multicast is a form of multicasting messages that allows for great flexibility in message sending and adding and dropping nodes from the network. A message can be sent to any node through any node, and nodes are able to join and leave the DHT without compromising the network connectivity. Commands directing how nodes in the DHT behave are called Mcast commands. Messages to be sent through the network are called Mcast messages.</p>
            <p>All nodes in a DHT can accept Mcast commands either for themselves or other nodes in the network. The various commands and their structure can be examined below:</p>
            <li>Create(M_ID)</li>
            <li>Join(M_ID and the process that wants to join)</li>
            <li>Leave(M_ID and the process that wants to leave)</li>
            <li>Mcast(ID and the message to be sent)</li>
            <li>Destroy(M_ID)</li>
            <p></p>
            <P>Once a DHT is established it is easy for nodes to join and send messages. If a node needs to send a message to another node, it will use one of the above commands and send it to the next node in the network. That node will forward to the next and so on, until the destination node receives the message. If a node wants to leave the network, it forwards all of its children to the next node in the network</P>
            <p>Whichever node you sent a message or command in through becomes the root for that particular multicast group.</p>

            <p class="font-weight-bold">12. Gossip based dissemination:</p>
            <p>Gossip based dissemination is a form of sending messages over a network. It is easy to implement, robust, and we only need local information at each node. A message is sent into the network through a single node. That node passes the message to its neighbors. There are two types of nodes in this messaging construct:</p>
            <li>Infected: Nodes that have seen a message</li>
            <li>Susceptible: Nodes that have not yet seen a message</li>
            <p></p>
            <p>Nodes communicate by pushing and or pulling from each other (one directional communication) or by exchanging messages between each other (bi-directional communication).</p>
            <p>Push only communication is not suited well for applications that require rapid updates because only infected nodes can pass the message along. As the message infects more nodes, the probability of sending a message to an already infected node increases.</p>
            <p>Pull only communication is best suited when there are already a large number of infected nodes. Susceptible nodes pull updates from infected nodes.</p>
            <p>Both push and pull are fairly easy to implement whereas push-pull requires a little more work. Push-pull runs in O(log(N)) rounds. A round is defined as all the event where all nodes have seen the message.</p>
            <p>The easiest way to understand this concept is to consider a neighbor telling their neighbor the hot news. The message continues to spread until a neighbor. Once enough neighbors report they have heard the message they can stop trying to spread it because it is now the old news.</p>

            <p class="font-weight-bold">13. Dynamic Host Configuration Protocol (DHCP):</p>
            <p>There are a finite number of IP addresses available and organizations often purchase or use blocks of IP address ranges. Statically assigning an IP address to all users in an organization ahead of time is administratively impossible. A much more efficient solution is to use a DHCP server to dynamically assign a user an IP address on demand.</p>
            <p>When a user turns on a device, the DHCP client on that device sends a message to the DHCP server asking for an IP address. The DHCP server will select from an open pool and return an available IP address along with other bits of information such as the default gateway, subnet mask, and lease length. In general, the DHCP server for large organizations will return a real IP address.</p>
            <p>There are three ways in which DHCP can assign IP address:</p>
            <li>Dynamic: Pick the first available address out of the pool</li>
            <li>Automatic: Once an address has been assigned to a client, remember it, so it can be assigned the next time the client connects</li>
            <li>Static: Preconfigured based on the MAC address of the client, and always assign the same IP address</li>
            <p></p>

            <p class="font-weight-bold">14. Network Address Translation (NAT):</p>
            <p>NAT is conceptually similar to DHCP however the IP address assigned are contrived i.e. not real. The best example is to look to our home networks. Our routers obtain a real IP address from our internet service providers. The routers then use NAT to return a contrived IP address to all of our local devices. This allows for a lot more devices to be used than exist IP addresses. So how do our clients communicate with other devices outside of the local network? To answer that question we need to remember the four pieces of information required for two machines to talk to each other, the client IP address and port number and the server IP address and port number. NAT will store in a table the contrived IP address it has assigned to a local client along with the local clients port number. It will then record the IP address and the port number of the remote machine. When messages come in from a remote machine, the NAT will match the conversation in its table based off the four pieces of information, and route the conversation to the correct local client. Neat!</p>

            <p class="font-weight-bold">15. Virtual Private Network (VPN):</p>
            <p>A VPN is a tunneled connection between two devices. If the client is remote, it can use a VPN to connect to the home network, where it will appear as if it is geographically and or physically connected to the network. The client will take a packet of data and encrypt the whole thing. It will then wrap that encrypted packet in a generic packet with pre-assigned routing information that is known only by the client and remote network. The remote network receives the generic packet, decrypts the internal packet, and routes it accordingly. They key here is that the only exposure on the network are the generic packets. All of the generic packets are routed through proxies so it is not possible to tell who the original sender is and who the original receiver is. So you can clearly see these generic packets but you cannot tell what is in them or who they are from and to.</p>

            <p class="font-weight-bold">16. Network Time Protocol (NTP):</p>
            <p>is a technique to combat the concept of there is no global clock. In its most basic form we need both the client and the server to keep track of the time in which the request was sent, the time in which the client received the response, and the request processing time server side. We can then take the difference of the two, calculate the delays due to traversing the network, add them together and apply the average to the client time.</p>

            <p class="font-weight-bold">17. The Berkely algorithm:</p>
            <p>The Berkely algorithm is another technique for combatting the concept of there is no global clock. With this approach we have a time daemon that asks all of the machines on a system to provide their current time. Once all systems have answered, the time daemon calculates the average difference between them all and provides instructions for each machine to adjust its clock. However, the clocks cannot simply be adjusted to the newly provided time because we cannot rewind time, and it is dangerous to skip time. Skipping time especially problematic for processes that are time based. If a machine is told to skip ahead, a process may miss execution steps, leading to instability. The solution is to extend or compress time on each machine until the appropriate adjustment has been made.</p>

            <p class="font-weight-bold">18. Lamport’s clock:</p>
            <p>Lamport’s clock is a technique for adjusting time in distributed systems. First we need to understand the happen-before relation:</p>
            <li>If we have two events, B and C that occur in the same process, and B happens before C, then the statement B implies C is true</li>
            <li>If we have two events, B and C, that are parts of messages from different processes, and B is the event of a message being sent and C is the event of a message being received, then B implies C is true</li>
            <li>If we have two events B and C, that are parts of different processes, and these two events do not exchange messages, the we cannot say that B implies C</li>
            <li>Finally a recap of the properties of a transitive relationship, if A implies B, and B implies C, then A implies C</li>
            <p></p>
            <p>Each process in a distributed system has its own clock and we know that there can be variance between each of the clocks. If we consider the example of sending a message from the application layer to the network layer in a distributed system, we can implement Lamport’s clock in the middleware layer. A clock is maintained in the middleware layer and time for all processes only moves forward when Lamport’s clock moves forward. Before a process executes an event, it takes the value of the clock and increments it and then adds that time stamp to the message and sends it off. The receiving process then adjusts its clock accordingly and repeats the steps when it next sends a message. Clock adjustments are made by shrinking or expanding the local time to match that of Lamport’s clock.</p>

            <p class="font-weight-bold">19. Middleware:</p>
            <p>Middleware is a layer in a distributed system that allows a process to act like it is running on a single local machine. Middleware sits between the various applications of the distributed system and the environments of each of the local systems that play a part in the whole. Middleware acts as a uniform interface for the distributed system, thus allowing programmers to not be concerned with the various computer architectures through-out the distributed system. Let’s consider the following simple example:</p>
            <p>We have three machines, A, B, and C. Each of the machines have different operating systems, kernels, etc.  On top of the operating system and network interface for each of the machines, sits the middleware layer. Machine A could spawn a process that talks directly to machine B by sending messages up to the middleware layer, which directs the message over to machine B. The application layer sits on top of the middleware layer. Machine C could spawn a process that needs to communicate with the application layer first, before sending the result to machine A. Machine C would send the message to the middleware layer, which then sends the message to the application layer, were an event occurs, and the result is then sent back down through the layers to machine A. Machine A, B, and C, can technically not have knowledge about each other or that they exist. It is the middleware’s job to keep track of such details.</p>

            <p class="font-weight-bold">20. Graphene devices:</p>
            <p>Graphene devices in relation to distributed systems can be summarized with the following statement: Get the brain waves out to control devices.</p>
            <p>The human brain can be considered as housing the computing power equivalent to 50 million desktop computers. We are able to captures information from our brains using probes that are either stuck to our heads or in some cases implanted directly into the brain. With one to two probes stuck to our head, we can fly airplanes through hoops in a video game. Graphene is a fairly new material comprised of stacked carbon atoms and it is very lightweight, very thin, and very strong. Graphene devices now exist that have 5000 probes and are capable of harvesting vast amounts of computing power from the human brain. This has huge ethical implications that must be addressed. That power can in theory be exploited if it joins a distributed system. The ethical questions to answer include how can we prevent the exploitation of human beings that are in less privileged states from being forcefully or unknowingly added to a distributed system for the sole purpose of using the immense computational power that resides between their ears.</p>

            <h3>Forum Posts:</h3>
            <p>As stated in my submission for the five expert three hello assignment, the combination of my day job, a full academic schedule, and a number of other factors, was cause for my limited activity on the discussion forums. Again, I appreciate how valuable that community discussion is. In accordance with the main theme of distributed systems; there is always a compromise, I found the middle ground. I relied on my personal network rather than the discussion forms to help deepen my understanding of distributed systems. Through-out the quarter, I shared with my colleagues, friends, and family, the very well prepared and presented materials from this course. In that sharing and related discussions, I certainly achieved a deeper understanding of distributed systems. The blockchain assignment was cause for several amazing conversations, including teaching colleagues who were not computer scientist just how all the moving pieces fit together.</p>
            <p>With that said, below are my limited contributions to the discussion forms:</p>

            <p class="font-weight-bold">First say hello:</p>
            <p>
                I’m Brandon Markwalder and I’m in the online section. I’m in my final year of the MSCS program and my concentration is data science. My undergrad is in health care administration and I spent a decade as a health care technology account manager. I began a career transition because the travel was growing old and I found that in my day to day interactions with my colleagues, I was more drawn to the bright and talented folks that built the products that I was selling and renewing.
                I currently work for the Kellogg School of Management at Northwestern University where I spend my time working to improve the computing operations team (helpdesk) in how they operate and deliver support. On top my day to day, I’m afforded the opportunity to wade through buckets of data in search of better processes in the way support is delivered – in other words, it is a lot of fun and machine learning is my friend right now.
                In my spare time, I chase a four year old around, I bake sourdough bread, and I run, and ride my bike. The recent cold has not stopped me from running or riding every day. My toddler especially likes the frozen eye lashes I bring home after running in -10 F.
            </p>
            <p></p>

            <p class="font-weight-bold">First say hello response:</p>
            <p>I had not thought about the X-Ray Audio Project or how neat I thought it was that folks figured out a way to continue to share music in some of the dark times. I cannot remember exactly where I first stumbled across the concept of bootleg x-ray records, but in my quick search just now I discovered the TED talk by Stephen Coates. Thank you for bringing this concept back to the for-front of my mind. So neat!</p>

            <p class="font-weight-bold">Expert post one:</p>
            <p>Thomas and Michael,
                As Michael said, IDE's and text editors alike tend to elicit great emotion and passion from folks especially with respect to which is the best solution. I've used four or five Java IDEs and have settled on IntelliJ only because JetBrains makes a wide range of IDEs and its nice to have a standard look, feel, and functionality, across development environments for the various languages that we all write in. There is a community edition, but you can also sign up for the pro editions free by using your DePaul email address at the following URL: https://www.jetbrains.com/student/</p>

            <p class="font-weight-bold">Expert post two:</p>
            <p>Part 8: Bragging rights</p>
            <p>I decided to have a little fun with wireshark and SSH. I connected to my VPS via and SSH connection and took a look at the traffic. It was neat to see the client and server establish contact. The two sides first identified themselves including what software and versioning they are running. The client then sent a Key Exchange Init packet which contains useful information including the various encryption algorithms available to choose from. The Server then acknowledges receipt of that information and I believe the two sides agree on what algorithms to use for the SSH session key. Next the client sent information about its private RSA key including its size in bits along with the min and max sizes available for use. The server responded with a multi precision integer length and a DH GEX function. The two sides then use the Diffie-Helman algorithms, recently exchanged information including the agreed upon functions, and stored keys, to generate an SSH session key. The key is generated on either side independently. The client then sent a packet stating it had new keys to send. The following packet from the client was encrypted with the following server response being encrypted. All of the following packets were sent encrypted.</p>
            <p>If I was running SSHv1, in theory I would be able to decrypt packets just by having the private key. It's another story with SSHv2 and the Diffie-Helman algorithms. Because I have access to both ends of the connection, I suppose with enough time, I could put together the four pieces of the puzzle to decrypt the data, but that would involve capturing certain bits of data from the server end and computing the independently generated session key.</p>
            <p>An interesting observation was that I run my VPS on an alternate SSH port (which is kind of pointless) but before I updated the SSH port in wireshark to match that of my VPS, all of the encrypted packets were represented as continuous data. After updating the port number however, a huge amount of detail was visible about the exchange between the two machines, including the back and forth while establishing the encryption. It was a lot of fun to see and I look forward to examining the capture in much greater detail down the road.</p>

            <h3>Lecture notes:</h3>

            <p class="font-weight-bold">Lecture 01:</p>
            <p>There is almost always a compromise and there is no global clock. The following concepts are important but will not be covered in class and they will likely make good 20 concepts topics:</p>
            <li>Parallel Computing</li>
            <li>Grid Computing</li>
            <li>Cluster Computing</li>
            <li>Distributed Operating Systems</li>
            <li>Shared memory Systems</li>
            <li>Distributed Algorithms</li>
            <p></p>
            <p>The motivation behind distributed systems is to protect sensitive applications while leaving less sensitive applications more accessible.</p>
            <p>Boundary policies are like proxies.</p>
            <p>Middleware is the layer of software running independently on each computer but makes it appear as though the application is running on a single system.</p>
            <p>Transparency is an effort to make the distributed system invisible to the user, so the user cannot see the distributed system. Transparency is not always a good thing.</p>

            <p class="font-weight-bold">Lecture 02:</p>
            <p>Anyone can write to open systems. The interface is defined and anyone can write programs in any language that is able to talk to the system as long as they follow the rules. If we stick to the defined interface, the implementation remains open. Interface definition languages allow for this concept to work. Remember that the whole point of an open system is maintaining that policy is separate from implementation. Open systems should follow four basic principles:</p>
            <li>They must include defined requirements that allow all parties to implement their solutions</li>
            <li>Once defined, remain stable over the development period</li>
            <li>Interfaces are publically available, hence the word open in open systems</li>
            <li>There is not a single party that holds control over the system</li>
            <p></p>
            <p>When working with open systems, scalability should be of top concern. Especially in the administration of the system, which is often the bottle neck when you take a small system and scale it up. An example provided in class was taking our class of 70-80 students and blowing it up to 1000 students worldwide. Suddenly, we need multiple graders, which is cause for oversight to ensure that grading is performed in a consistent manner. Content suddenly needs to be evaluated to ensure it can legally be transmitted worldwide, etc.</p>
            <p>Fully distributed algorithms are difficult to implement for a variety of reasons, mainly because there is no global clock. General properties of a fully distributed algorithm are:</p>
            <li>There does not exist one machine that has all of the information about system, specifically the current state of the system</li>
            <li>Local machines will make decisions based only on the information that resides on the local system</li>
            <li>Failure of a single point will not make the entire system fail</li>
            <p></p>
            <p>Fully distributed algorithms are often buggier and slower, than local solutions. These properties are difficult to wrangle, so what is the incentive to attempt to implement a fully distributed algorithm? Because when they do work, they are awesome, so you should give it a shot.</p>
            <p>Thick vs Thin clients: Thin clients have little code stored client side resulting in more data transfer, which brings with it risk as there are more opportunities for exposure of data/information. Thick clients have more code stored client side, leading to greater risk of out dated code which can lead to insecure code remaining out in the wild.</p>
            <p>Synchronous vs Asynchronous: Synchronous are easy on a local system. If a client blocks on an open system that leads to trouble. Blocking calls are synchronous, meaning the caller and the called wait for each other to complete their tasks. If a client is blocked we cannot tell if the server blew up, so we should use an asynchronous call. In an asynchronous, the caller does not wait for the called to respond, it continues down its path. Asynchronous calls often require more complex logic.</p>
            <p>Latency is the amount of time for an empty packet to get from here to there.</p>
            <p>In transactions there is a before, and after, and nothing in between. To define that more concretely, think of the example provided where a user books a hotel, flight, and car rental. All three bookings are first not booked, then they are all booked. The transaction fails if only the hotel is booked.</p>

            <p class="font-weight-bold">Lecture 03:</p>
            <p>In distributed systems we do not have shared memory. Inter process communication (IPC) is a piece of cake on a local system because you can just allocate a block of memory to be shared between the two processes. On a distributed system, things get trickier because there is no shared memory. So how do you accomplish IPC in a distributed system? You send a message.</p>
            <p>Context switching is the action of giving each process a turn on the CPU. The operating system will try to balance everything out and give each process a fair share of time. A process will execute a handful of instructions, then it is place on hold while the next process is loaded into the registers. The operating system can do a context switch at any time.</p>
            <p>Atomic action is a unit that cannot be broken down to smaller parts that still makes sense. Generally we want to complete an atomic action before a context switch.</p>
            <p>Critical sections are blocks of code that cannot be interrupted by a context switch.</p>
            <p>Semaphores are the gatekeepers of context switching. If they report true, that indicates that a critical process is in action and that a context switch should not happen. This is the basis of the Test and set principle. Test is when you look at the semaphore. If true, do something else or wait, if false, then proceed into the context switch. Once a critical section is loaded in to the CPU, set the semaphore to true to prevent interruption.</p>
            <p>Shared memory in a distributed system. If it were practical to implement, distributed shared memory would solve a lot of problems. To implement, you could set up a large block of memory, assign all machines a range of universally unique identifier (UUID), and then they could all talk to each other with the theoretical ease of processes running on a local system. The pitfalls of this concept are:</p>
            <li>Buggy and slow</li>
            <li>Still have to do work to implement IPC</li>
            <li>Not at all efficient</li>
            <li>A lot of overhead to make sure programs are running in a coordinated manner (predict how they will run)</li>
            <p></p>
            <p>There are two main types of messaging protocols, Transmission Control Protocol/Internet Protocol (TCP/IP) and Universal Datagram Protocol (UDP). TCP/IP is much more reliable, as it involves sending bursts of packets and waiting for them to be acknowledged as received on the other end, and the re-sending lost packets as needed. UDP can be faster because you send and forget.</p>
            <p>Messages are essential to open systems. They allow all of the process and moving bits to communicate. The following problems are common when working with messages in distributed computing:</p>
            <li>Receiving buffers fill up and the sender can no longer wait, so the message is sent anyway and lost in transit</li>
            <li>Messages and acknowledgments are lost in transit</li>
            <li>Messages do not arrive on time or in the wrong order</li>
            <li>Processes do not communicate what they are doing</li>
            <li>Both the sender and the receiver need to remain active during messaging</li>
            <p></p>
            <p>Message Oriented Middleware (MOM) is a solution to some of the messaging problems. We off load the burden of coordinating messages onto a middleware layer. There is a loss of control when using a MOM. For example, you may send a message, and not know if it was lost because the MOM is storing the message until the receiver is available to receive it.</p>

            <p class="font-weight-bold">Lecture 04:</p>
            <p>Revisiting UDP and TCP/IP. Remember the common theme that there is always a trade off or compromise and you must evaluate the needs of the system when choosing how to send messages. UDP is fast but suffers from data loss. TCP/IP is slow but very reliable. There are several levels of compromise between the two protocols if needed.</p>
            <p>HTTP and TCP. Why was HTTP slapped on top of TCP? Because TCP was already there and can transfer any kind of data in packets. We do not need to worry if our HTTP packets will arrive, that is TCPs job.</p>
            <p>Revisiting problems with messages: They can get lost, buffers fill up, acknowledgments can get lost, messages can be delayed in delivery or they can arrive in the wrong order. In certain systems it gets tricky to coordinate messages as the cross each other in transit over the network.</p>
            <p>Producer and consumer coordination. The producer writes or sends until it catches the consumer and the consumer reads or receives until it catches the producer. Think about this like two processes working on the same array or block of sequential memory. When either hits the end of the array, they loop back to the beginning. When either process catches the other, it blocks, until the other process has moved further down the circular memory structure. Put in concrete form, when the consumer catches the producer, it blocks waiting.</p>
            <p>Healthcare and distributed systems – Important points to consider when evaluating where to make the compromise:</p>
            <li>Where to store data, server or client side? Server side comes with security and liability risks. Client side comes with implementation and data availability issues</li>
            <li>Stability of the system and making sure it can transmit crucial information precisely when it needs to be transferred</li>
            <p></p>
            <p>Data-centric intelligent databases have two key concepts to study:</p>
            <li>Modus ponens states that when we know A implies B, and A is true, the B is also true</li>
            <li>Resolution states that when we know X or Y is true, and we also know that either Y is not true or Z is true, then we can deduce that either X or Z is true</li>
            <p></p>
            <p>MIME types are used to let different consumers know what kind of data to expect.</p>
            <p>Attribute value pairs are simply the name of something and its value.</p>

            <p class="font-weight-bold">Lecture 05:</p>
            <p>Multi-tiered architectures refer to the client server relationship and how we distribute an application between them. The client will house the user interface which makes request operations to the application server which then makes a request operation to the database server. The database server returns the requested data, and then the application server will execute its operations on the data and return the result to the client. There is a waiting step between each step, and we again have to consider the core concept of comprise with developing these systems. Careful attention must be paid when deciding how to organize an application in regards to thick or thin clients / thin or thick servers.</p>
            <p>There are two types of operations:</p>
            <li>Idempotent: Return the account balance – this operation can be repeated many times if the message is lost or delayed. The worst that will happen is the account balance is returned twice.</li>
            <li>Execute only once: Transfer $323k from account B to account C. If the message is lost and a new message is sent, it becomes a big deal if/when they are both received as the transaction should only be executed once.</li>
            <p></p>
            <p>Processes are expensive but independent. Threads are cheap but they share resources. If a thread goes down, it takes its friends with it, often crashing the system. Processes do not impact each other so we can lose a processes without losing the system.</p>
            <p>Kernel space is where we execute system instructions. User space is where we execute general instructions.</p>
            <p>An X windows system is a dynamic system where the server can become the client and the client can become the server.</p>
            <p>Deamons are autonomous processes running in the background – think of the voice in your head that reminds to you mail that letter when you get home.</p>
            <p>Super servers are able to determine when there is a need for more resources or triage task specific resources. A super server is able to start up servers on demand and shut them down when they are not needed.</p>
            <p>Code migration and mobility. Weak mobility is when you ship all code to a new machine and start it from the beginning. Weak mobility is easy to implement and has a fast start up time. Strong mobility is when you ship an operation across the network while it is still running. Strong mobility requires the packaging and running processes, data structures, etc. sending to the new machine, and starting the process where we left off form the old machine, very hard to implement but very important for critical operations – think space flight and transferring to a new system from a failing system.</p>
            <p>Synchronous and Asynchronous calls are fundamental parts of distributed systems. With a synchronous call we make a call from the client and then wait for the response. With asynchronous calls, the client makes a call and carries on. This can lead to more efficient systems but requires more careful planning and implementation. A balance can be found by making an asynchronous call and then waiting for a short while before moving on to other tasks. This compromise accounts for slight delays in network traffic before moving on to other tasks.</p>
            <p>What do we need to uniquely identify a packet? The local port and IP address and the remote port and IP address.</p>

            <p class="font-weight-bold">Lecture 06:</p>
            <p>More on Marshalling. Automated marshalling is next to impossible because it requires a low level algorithm to do the marshalling while it does not know anything about the data, what architecture it is coming from, and what architecture it is going to. You can be sure that you can marshal any data structure possible as long as we satisfy one condition. It has to be an integer. Doing so puts the burden of marshalling on the programmer to figure out. Again, automated marshalling is hard if not impossible.</p>
            <p>Introspection is when data structures or objects carry with them information about the class. This information needs to be marshalled too. Java is handy as it has libraries supporting introspection and serialization.</p>
            <p>Common data representation (CDR) assumes both parties know about the data types and data structures and sends only the data. CDR is easier to implement but more “flabby”. CDR is also more efficient when it comes to transmitting data across a network. Common Object Request Broker Architecture, Common Data Representation (COBRA) is a common framework for coordinating computers over a distributed system. It contains 15 primitive types in addition to constructed data types and can be used by many different platforms on a system, however there is no type information transmitted, so each system must know what types are being used.</p>
            <P>Request reply communication was covered in this lecture and is detailed in the 20 concepts section.</P>
            <p>Client stubs and server skeletons are a way of making remote procedure calls. The client wraps the call in a subroutine called a stub. The stub’s job is to make the call look like it is being executed on the local system. The client sends a stub to the server. The server skeleton unpacks the stub to make the call look like it is being executed on the local server environment. The call is processed and executed, and the result is passed through the server skeleton and wrapped in a stub and sent back to the client.</p>
            <P>When we have more complex distributed systems, rather than have just one server, we can have a server to which clients connect to first. This server then routes the request to the appropriate server for example, a database server. This collection of backend servers is called a service.</P>
            <P>A note to remember about parameter passing. By default, remote machines send a reference to objects to the server. In processing the request, the server will only retrieve an object if it needs it by requesting a copy of the object itself. This can save a lot on network traffic, however, the downside is that the server may stop everything it is doing while it waits for the requested object to arrive.</P>
            <P>Data streams were covered in this lecture and are detailed in the 20 concepts section.</P>
            <p>Network level support DiffServ on IP is a way of indicating more important packets in a data stream by adding a couple of bits to the front of the packet.</p>

            <p class="font-weight-bold">Lecture 07:</p>
            <P>This lecture was mostly review so the notes will be kept to a minimum.</P>
            <P>User level threads are cheap, kernel level threads are in between, and processes are expensive.</P>
            <p>The four properties of distributed algorithms are:</p>
            <li>There is no global clock</li>
            <li>One processes failing does not bring down the system</li>
            <li>They operate on local data</li>
            <li>No machine has complete or global knowledge of the entire system</li>
            <p></p>

            <p class="font-weight-bold">Lecture 08:</p>
            <p>When talking about security protocols we often tell stories using contrived characters whose names follow a common theme as outlined below:</p>
            <li>Alice is the first party</li>
            <li>Bob is the second party</li>
            <li>Carol is the third party</li>
            <li>Dave is the forth party</li>
            <li>Eve is the eavesdropper</li>
            <li>Mallory is the malicious attacker</li>
            <li>Sara is a server</li>
            <P></P>

            <P>A related <a href="https://xkcd.com/1323/">xkcd</a></P>
            <p>Encryption is covered in detail in the 20 concepts section.</p>
            <p>Application level multicasting (ALM) is a way to send messages to a node in a network. ALM can be setup as a tree where each node has a distinct path or as a network where nodes have many paths between each other. The latter is more robust as we can still communicate across the network if a node fails.</p>
            <p>There are different approaches to distributing information through an ALM. The anti-entropy model involves a given node P picking another given node Q and random and then exchanging information. No P can either push information to Q or pull information from Q or the two nodes P and Q can exchange information bi-directionally between each other.</p>

            <p class="font-weight-bold">Lecture 09:</p>
            <p>DHCP is used to assign real IP address to requesting clients on demand.</p>
            <p>NAT is used to assign contrived IP address to requesting clients on demand.</p>
            <p>Mobile IP addresses are tricky. IP addresses are geographically fixed, which means each region has a block of IP address. Mobile devices are not geographically fixed so they rely on home agents and foreign agents. Home agents act as a proxy and route the traffic to where ever the foreign agent is currently at. Home agents require current information about the IP location of the mobile device. The home agent wraps packets in a mobile IP address whereas the foreign agent unwraps them on the local mobile device. As address change, the home agent needs to be updated.</p>
            <p>Mobile agents are processes that help a remote process by doing tasks on their behalf. This construct can lead to more efficient applications as local resources are often cheaper than remote ones. Mobile agents are tricky to implement and keeping things secure can be a challenge.</p>
            <p>IP security is cheap security that operates at levels just below TSL, SSL, SSH, etc. VPNs are based off of IP security.</p>
            <p>Bluetooth is a low power consumption method for devices to talk to each other. The slave device is turned off and wakes up at pre-agreed upon intervals of time to listen for a connection. If no connection requests are present, it goes back to sleep. If it hears a connection request, it will establish a connection with the requesting master devices. Devices can be either slaves or masters depending on how they are configured. Because of the sleep period of multiple seconds, they are not suited for communication that begins and ends very quickly, for example toll road readers and transponders.</p>
            <p>There is no global clock. Various techniques for dealing with this are network time protocol, the Berkely algorithm and Lamport’s clock.</p>
            <p>We cannot adjust time by simply skipping forward or backward. First, it is impossible to go backwards. Secondly, if you skip forward, you can skip important system based events. An abstract example is that of the nuclear dead man switch. If there is a person whose job is to push the button if he does not hear the do not push that button messages every 15 seconds, then the button will be pushed if the clock is adjusted by skipping ahead more than 15 seconds. A concrete example is that many distributed systems have built in time-outs for processes to simulate a synchronous system, skipping time may cause those processes to never time out.</p>

        </div>
    </div>
</div>


</body>
</html>